---
layout: default
---

# 嵌入式AI 双周简报 (2017-09-05)

## 业界新闻

- [机器之心独家解读：华为首款手机端AI芯片麒麟970 | 机器之心](https://mp.weixin.qq.com/s?src=11&timestamp=1504602412&ver=374&signature=-Fmq9sTNai361IggmAHHH3xjBTZ3IpqijcLRlyYbQDGyp-fuNhRu95g2AhtsR0Xlxf7WWGuNHWb3CbtP5O4hYzzGT9kGg2N5BGW67ZtA1ww2ck2KF5fgAu5zNpo2bfjT&new=1)</br>
简评：华为与寒武纪进行了深度的芯片设计合作，华为也是第一次在移动设备层面上把神经网络模型的硬件计算加速能力融合进芯片中去。双方团队在 AI 计算处理方面进行了联合开发与优化，除更高效灵活的异构计算来最大化发挥 CPU/GPU/ISP/DSP/NPU 的性能外，首次集成专门用于神经网络任务处理的 NPU（Neural Network Processing Unit）计算单元，其加速性能和能效比大幅优于 CPU 和 GPU。  
- [如何评价华为海思麒麟970处理器？ | 知乎](https://www.zhihu.com/question/57283387)</br>
简评：五个要点：CPU、GPU：重点是降功耗；ISP、DSP、Codec、协处理器；通讯基带：比「千兆 LTE」更快；10 纳米制程，比骁龙 835 还多的 55 亿个晶体管；NPU：首款内置在手机 SoC 中的人工智能芯片。  
- [Deep Learning的IR“之争” | 唐杉 StarryHeavensAbove](https://mp.weixin.qq.com/s/0iDVjaucRUpn2UrVBuQ-oQ)</br>
简评：Google Tensorflow XLA (Accelerated Linear Algebra)就使用了LLVM IR（Intermediate Representation）。而它的“竞争对手”，刚刚发布的TVM/NNVM，则是“Tensor IR Stack for Deep Learning Systems”。IR是什么？为什么重要？我们一起来看看。
- [微软揭晓 Brainwave 人工智能系统，可实现超低延迟 | DeepTech深科技](https://mp.weixin.qq.com/s/XS_9XoQ6ZE1grmVtwJJdbA)</br>
简评：今日，微软在 HotChips 大会上正式揭晓了 Brainwave 系统，该产品是微软加入人工智能硬件竞赛的首发产品。微软表示这款高速度、低延迟的 AI 专用芯片系统可以为机器学习开发者们提供超越 GPU 的性能。
- [一文看懂人工智能芯片的产业生态及竞争格局 | 雷锋网](https://www.leiphone.com/news/201709/uuJFzAxdoBY7bzEL.html)</br>
简评：
- [向手机端神经网络进发：MobileNet压缩指南 | Matthijs Hollemans 机器之心](https://mp.weixin.qq.com/s/f3bmtbCY5BfA4v3movwLVg)</br>
简评：
- [AR资深研究员Matt Miesnieks解读ARCore如何好过ARKit？ | Matt Miesnieks ARC增强现实](https://mp.weixin.qq.com/s/MXiHi8wVJX9JYV3DeQoNBA)</br>
简评：
- [Compressing deep neural nets](http://machinethink.net/blog/compressing-deep-neural-nets/)</br>
简评：
- [Myriad X Moves Computer Vision and Deep Learning Down to the Bare-Metal](https://blog.hackster.io/myriad-x-moves-computer-vision-and-deep-learning-down-to-the-bare-metal-7eab1b0a0f52) [video](http://weibo.com/tv/v/Fk30ErZPA?fid=1034:c37df410f85d0942997922d3e295b738)</br>
简评：
- [Wave公司发布数据流处理架构DPU: 不含CPU，超越GPU 1000x | Nicole Hemsoth　新智元](https://mp.weixin.qq.com/s/bL1PoUjZ_sH2VKcBxI6N5A)</br>
简评：
- [This Small Quantum-Computing Firm Wants to Supercharge AI Startups | MIT Technology Review](https://www.technologyreview.com/the-download/608730/this-small-quantum-computing-firm-wants-to-supercharge-ai-startups/)</br>
简评：伯克利量子计算公司Rigetti打算为40家机器学习初创公司提供AI计算支持
- [取代MNIST？德国时尚圈的科学家们推出基准数据集，全是衣裤鞋包 | 量子位](https://mp.weixin.qq.com/s/Pidt3nW5N7dU0P4bm9sIHA)


## 论文

- [[1708.08917] CirCNN: Accelerating and Compressing Deep Neural Networks Using Block-CirculantWeight Matrices](https://arxiv.org/abs/1708.08917)</br>
简评：
- [[1708.05963] Neural Networks Compression for Language Modeling](https://arxiv.org/abs/1708.05963)</br>
简评：
- [[1707.06168] Channel Pruning for Accelerating Very Deep Neural Networks](https://arxiv.org/abs/1707.06168)</br>
简评：

## 开源项目

- [OAID/YSQfastfd: A fast binary library for face detection and face landmark detection in images. No float point operations, especially suit for low cost ARM CPUs, The highest accuracy on FDDB among non deep learning methods](https://github.com//OAID/YSQfastfd)</br>
简评：
- [shiyangdaisy23/vqa-mxnet-gluon](https://github.com/shiyangdaisy23/vqa-mxnet-gluon)</br>
简评：
- [kazizzad/DQN-MxNet-Gluon: DQN-MxNet-Gluon](https://github.com/kazizzad/DQN-MxNet-Gluon)</br>  
简评：
- [longcw/pytorch2caffe: Convert PyTorch model to Caffemodel](https://github.com/longcw/pytorch2caffe)</br>
简评：
- [HalfdanJ/ofxARCore: Experimental addon for openFrameworks to use ARCore on Android devices](https://github.com/HalfdanJ/ofxARCore)</br>
简评：Android平台基于Google ARCore的AR框架示例
- [healthDataScience/deep-learning-HAR: Convolutional and LSTM networks to classify human activity](https://github.com/healthDataScience/deep-learning-HAR)</br>
简评：
- [rwightman/pytorch-dpn-pretrained: Dual Path Networks (DPN) supporting pretrained weights converted from original MXNet implementation](https://github.com/rwightman/pytorch-dpn-pretrained)</br>
简评：
- [Deploying your Keras model using Keras.JS | Becoming Human](https://becominghuman.ai/deploying-your-keras-model-using-keras-js-2e5a29589ad8) [[demo]](https://greenscreen-ai-client.boorgle.com/#/) [[code]](https://gitlab.com/fast-science/background-removal-vue)</br>
简评：用Keras.JS部署Keras模型
- [likedan/Core-ML-Car-Recognition: A Car Recognition Framework for CoreML](https://github.com/likedan/Core-ML-Car-Recognition)</br>
简评：Core ML汽车识别Demo
- [likedan/Awesome-CoreML-Models: Largest list of models for Core ML](https://github.com/likedan/Awesome-CoreML-Models)</br>
简评：Core ML模块大列表
- [Zhouaojun/Efficient-Deep-Learning: Related Paper of Efficient Deep Neural Networks](https://github.com/Zhouaojun/Efficient-Deep-Learning)</br>
简评：

## 博文

- [Deep Learning for Siri’s Voice: On-device Deep Mixture Density Networks for Hybrid Unit Selection Synthesis | Apple](https://machinelearning.apple.com/2017/08/06/siri-voices.html)</br>
简评：
- [CNN 模型压缩与加速算法综述 | 腾讯云](https://cloud.tencent.com/community/article/678192)</br>
简评：
- [吴恩达Deeplearning.ai课程 | 网易云课堂](https://mooc.study.163.com/smartSpec/detail/1001319001.htm)</br>
简评：永久免费！吴恩达刚公布的深度学习课程上线网易云课堂，在国内正式发布 Deep Learning（深度学习）微专业课程。
- [从零开始码一个皮卡丘检测器-CNN目标检测入门教程 | 知乎专栏](https://zhuanlan.zhihu.com/p/28867241)</br>
简评：用MXNet Gluon做图像深度学习，从零开始码一个皮卡丘检测器的CNN目标检测入门教程
- [Intel Nervana Tutorials | YouTube](https://www.youtube.com/playlist?list=PLXAoLgwZtKcgGE2-Wy23EUE4Q03s-YVwF)</br>
简评：Intel Nervana的Neon教程
- [Deep Learning Research Directions: Computational Efficiency | Tim Dettmers](http://timdettmers.com/2017/08/31/deep-learning-research-directions/)</br>
简评：
- [How much compute do we need to train generative models? | Dustin Tran](http://dustintran.com/blog/how-much-compute-do-we-need-to-train-generative-models)</br>
简评：
- [MIT 6.S094: Deep Learning for Self-Driving Cars](http://selfdrivingcars.mit.edu/)</br>
简评：
- [TensorFlow Deep Learning Optimized for Modern Intel Architectures | insideHPC](https://insidehpc.com/2017/08/deep-learning-optimized/)</br>
简评：
- [在机器学习的算法中， 矩阵运算的效率总是优于for循环吗？ | 知乎](https://www.zhihu.com/question/64659178)</br>
简评：
- [如何用FPGA加速卷积神经网络(CNN)？ | 知乎](https://www.zhihu.com/question/64411349)</br>
简评：
- [深度学习的异构硬件加速：TPU 特性与数据中心的 ASIC 应用（概述篇） | 腾讯云](https://cloud.tencent.com/community/article/120593)</br>
简评：
- [Semantic Segmentation using Fully Convolutional Networks over the years | Meet Pragnesh Shah](https://meetshah1995.github.io/semantic-segmentation/deep-learning/pytorch/visdom/2017/06/01/semantic-segmentation-over-the-years.html)</br>
简评：全卷积语义分割综述
- [A Guide to CoreML on iOS | Siraj Raval　YouTube](https://www.youtube.com/watch?v=T4t73CXB7CU)</br>
简评：iOS CoreML开发指南
- [CMU CS 11-747: Neural Networks for NLP](http://phontron.com/class/nn4nlp2017/)</br>
简评：CMU神经网络自然语言处理课程
- [Object detection: an overview in the age of Deep Learning | Tryolabs Blog](https://tryolabs.com/blog/2017/08/30/object-detection-an-overview-in-the-age-of-deep-learning/)</br>
简评：
- [一文详解YOLO 2与YOLO 9000目标检测系统 | 雷锋网](https://www.leiphone.com/news/201708/7pRPkwvzEG1jgimW.html)</br>
简评：
- [Optimize Deep Learning GPU Operators with TVM: A Depthwise Convolution Example | DMLC](http://tvmlang.org/2017/08/22/Optimize-Deep-Learning-GPU-Operators-with-TVM-A-Depthwise-Convolution-Example.html)</br>
简评：如何利用 TVM 优化深度学习GPU operator？教你用几十行Python代码实现2-3倍提升

----

Editor: 张先轶、袁帅

----

<a rel="license" href="http://creativecommons.org/licenses/by-sa/2.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/2.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-sa/2.0/">知识共享署名-相同方式共享 2.0 通用许可协议</a>进行许可。
